{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The face detector network is loaded using cv2.dnn.readNetFromCaffe and the model's layers and weights as passed its arguments.\n",
    "modelFile = \"models/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "configFile = \"models/deploy.prototxt.txt\"\n",
    "net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "\n",
    "# Represent the 8 age classes of this CNN probability layer\n",
    "AGE_INTERVALS = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)',\n",
    "                 '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "\n",
    "# The age detector network is loaded using cv2.dnn.readNetFromCaffe and the model's layers and weights as passed its arguments.\n",
    "AGE_MODEL = 'models/deploy_age.prototxt'\n",
    "AGE_PROTO = 'models/age_net.caffemodel'\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "age_net = cv2.dnn.readNetFromCaffe(AGE_MODEL, AGE_PROTO)\n",
    "\n",
    "# Capturing video or webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "\n",
    "    # Height and width of the image are extracted\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # To achieve the best accuracy I ran the model on BGR images resized to 300x300 \n",
    "    # applying mean subtraction of values (104, 177, 123) for each blue, green and red channels correspondingly.\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0,(300, 300), (104.0, 117.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Face detection is performed\n",
    "    faces = net.forward()\n",
    "\n",
    "    # For each face detected...\n",
    "    for j in range(faces.shape[2]):\n",
    "        confidence = faces[0, 0, j, 2]\n",
    "        # If the confidence is above a certain threshold\n",
    "        if confidence > 0.5:\n",
    "            box = faces[0, 0, j, 3:7] * np.array([w, h, w, h])\n",
    "            (x, y, x1, y1) = box.astype(\"int\")\n",
    "            # Face is extracted\n",
    "            img_face = img[y:y1, x:x1]\n",
    "            blob2 = cv2.dnn.blobFromImage(\n",
    "            image=img_face, scalefactor=1.0, size=(227, 227), \n",
    "            mean=MODEL_MEAN_VALUES, swapRB=False\n",
    "            )\n",
    "            # Forward propagation is performed\n",
    "            age_net.setInput(blob2)\n",
    "            age_preds = age_net.forward()\n",
    "            i = age_preds[0].argmax()\n",
    "            age = AGE_INTERVALS[i]\n",
    "            # A bounding box is drawn surrounding the face\n",
    "            cv2.rectangle(img, (x, y), (x1, y1), (0,0,255), 2)\n",
    "            # The estimated age range is printed\n",
    "            cv2.putText(img,str(age),(x1,y1),cv2.FONT_HERSHEY_DUPLEX,0.8,(255,255,255),2)\n",
    "            \n",
    "    # Display\n",
    "    cv2.imshow('Age Detector', img)\n",
    "\n",
    "    # Stop if escape key is pressed\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Release the VideoCapture object\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cc7f33b63d2a59a94cdd5905a9d69fd357a4127d48e5e12af1b13af86b584e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

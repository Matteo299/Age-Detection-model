{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 10:07:52.831554: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-31 10:07:52.831666: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-10-31 10:07:54.709299: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-10-31 10:07:54.754469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 897ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mSi Ã¨ verificato un arresto anomalo del kernel durante l'esecuzione del codice nella cella attiva o in una cella precedente. Esaminare il codice nelle celle per identificare una possibile causa dell'errore. Per altre informazioni, fare clic su <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a>. Per altri dettagli, vedere Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# The face detector network is loaded using cv2.dnn.readNetFromCaffe and the model's layers and weights as passed its arguments.\n",
    "modelFile = \"models/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "configFile = \"models/deploy.prototxt.txt\"\n",
    "net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "\n",
    "# Load the age detector model from disk\n",
    "model = load_model('models/cnn_model.h5')\n",
    "\n",
    "# Age ranges are defined\n",
    "ranges = ['1-2','3-9','10-20','21-27','28-45','46-65','66-116']\n",
    "\n",
    "# Capturing video or webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "\n",
    "    # Height and width of the image are extracted\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # To achieve the best accuracy I ran the model on BGR images resized to 300x300 \n",
    "    # applying mean subtraction of values (104, 177, 123) for each blue, green and red channels correspondingly.\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0,(300, 300), (104.0, 117.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Face detection is performed\n",
    "    faces = net.forward()\n",
    "\n",
    "    # For each face detected...\n",
    "    for j in range(faces.shape[2]):\n",
    "        confidence = faces[0, 0, j, 2]\n",
    "        # If the confidence is above a certain threshold\n",
    "        if confidence > 0.5:\n",
    "            box = faces[0, 0, j, 3:7] * np.array([w, h, w, h])\n",
    "            (x, y, x1, y1) = box.astype(\"int\")\n",
    "            # Face is extracted\n",
    "            img_face = img[y:y1, x:x1]\n",
    "            # Tranformed to grayscale\n",
    "            face = cv2.cvtColor(img_face,cv2.COLOR_BGR2GRAY)\n",
    "            # Resized and reshaped to fit the input layer of the network\n",
    "            face = cv2.resize(face,(200,200))\n",
    "            face = face.reshape(1,200,200,1)\n",
    "            # Normalized\n",
    "            normalizer = ImageDataGenerator(rescale=1./255)\n",
    "            facenorm = normalizer.flow(face)\n",
    "            # Prediction is performed\n",
    "            age = model.predict(facenorm)\n",
    "            # A bounding box is drawn surrounding the face\n",
    "            cv2.rectangle(img, (x, y), (x1, y1), (0,0,255), 2)\n",
    "            # The estimated age range is printed\n",
    "            cv2.putText(img,ranges[np.argmax(age)],(x1,y1),cv2.FONT_HERSHEY_DUPLEX,0.8,(255,255,255),2)\n",
    "            \n",
    "    # Display\n",
    "    cv2.imshow('Age Detector', img)\n",
    "\n",
    "    # Stop if escape key is pressed\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Release the VideoCapture object\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cc7f33b63d2a59a94cdd5905a9d69fd357a4127d48e5e12af1b13af86b584e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
